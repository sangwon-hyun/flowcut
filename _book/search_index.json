[["index.html", "Creating the flowcut R package 1 Introduction", " Creating the flowcut R package Sheng Jiang, Sangwon Hyun 2024-05-14 1 Introduction This package implements flowcut, a Bayesian mixture of experts model used for censored data (specialized for ocean flow cytometry). The documentation and package are both created using one simple command: litr::render(&quot;index.Rmd&quot;, output_format = litr::litr_gitbook()) This line is purely for testing (to be deleted later!). litr::load_all(&quot;index.Rmd&quot;)##, output_format = litr::litr_gitbook()) my_load &lt;- function(){ litr::render(&quot;~/repos/flowcut/index.Rmd&quot;, output_format = litr::litr_gitbook(minimal_eval = TRUE)) devtools::load_all(&quot;~/repos/flowcut/flowcut&quot;) } "],["package-setup.html", "2 Package setup", " 2 Package setup The DESCRIPTION file is created using this code. usethis::create_package( path = &quot;.&quot;, fields = list( Package = params$package_name, Version = &quot;0.0.0.9000&quot;, Title = &quot;flowcut&quot;, Description = &quot;Time-smooth mixture modeling for flow cytometry data.&quot;, `Authors@R` = person( given = &quot;Sangwon&quot;, family = &quot;Hyun&quot;, email = &quot;sangwonh@ucsc.edu&quot;, role = c(&quot;aut&quot;, &quot;cre&quot;) ) ) ) usethis::use_mit_license(copyright_holder = &quot;Sangwon Hyun&quot;) The following is what will show up when someone types package?flowcut in the console. #&#39; flowcut #&#39; #&#39; This package implements the `flowcut` method. #&#39; #&#39; @docType package This package will have some dependancies: library(tidyverse) library(ggplot2) usethis::use_package(&quot;tidyverse&quot;, type = &quot;depends&quot;) usethis::use_package(&quot;ggplot2&quot;) usethis::use_package(&quot;clue&quot;) usethis::use_package(&quot;glmnet&quot;) "],["helpers-functions.html", "3 Helpers functions", " 3 Helpers functions These are some helper functions that are needed for the MCMC. These functions are not documented for now. (TODO: do this.) #&#39; wcrossprod.fast &lt;- function(x,w.sqrt, weighting = TRUE){ if(weighting){ x &lt;- x*w.sqrt } if(min(dim(x))==1){ ret &lt;- x %*% t(x) }else{ ret &lt;- Rfast::Crossprod(x,x) } return(ret) } #&#39; self.crossprod &lt;- function(x){ if(min(dim(x))==1){ ret &lt;- x %*% t(x) }else{ ret &lt;- crossprod(x) } return(ret) } #&#39; logsumexp &lt;- function (x) { y = max(x) y + log(sum(exp(x - y))) } #&#39; softmax &lt;- function (x) { exp(x - logsumexp(x)) } #&#39; softmax2 &lt;- function(x){ return(exp(x)/sum(exp(x))) } #&#39; logMNdensity &lt;- function(y,invSig,logdet){ ## The term &quot;-log(2*pi)*d/2&quot; is omitted return(-t(y)%*%invSig%*%y /2-logdet/2) } #&#39; KL.MN &lt;- function(p,q){ sum(p*log(p/q)) } #&#39; pgdraw.mod &lt;- function(b,c){ if(b&gt;0){ ret &lt;- pgdraw(b,c) }else{ ## print(&quot;in pgdraw: b=0&quot;) ret &lt;- 0 } return(ret) } #&#39; SB2MN &lt;- function(pi.sb){ pi.sb &lt;- c(pi.sb,1) ## append 1 K &lt;- length(pi.sb) pi.mn &lt;- rep(0,K) pi.mn[1] &lt;- pi.sb[1] for(kk in 2:K){ pi.mn[kk] &lt;- pi.sb[kk]*(1-sum(pi.mn)) } return(pi.mn) } #&#39; MN2SB &lt;- function(pi.mn){ K &lt;- length(pi.mn) pi.sb &lt;- rep(0,K-1) pi.cs &lt;- cumsum(pi.mn[-K]) pi.sb[1] &lt;- pi.mn[1] pi.sb[2:(K-1)] &lt;- pi.mn[2:(K-1)]/(1-pi.cs[-(K-1)]) return(pi.sb) } #&#39; gamma2pi &lt;- function(gamma,Xp){ XpGamma &lt;- t(gamma) %*% Xp ## K-1 x T pi.sb &lt;- 1/(1+exp(-XpGamma)) return(pi.sb) } #&#39; dtaMatCensor &lt;- function(x,Cbox){ d &lt;- dim(x)[2] for(ii in 1:d){ x[,ii] &lt;- pmin(pmax(x[,ii],Cbox[ii,1]),Cbox[ii,2]) } return(x) } #&#39; censorIndicator &lt;- function(x,Cbox){ d &lt;- dim(Cbox)[1] if(dim(x)[2]!=d &amp; dim(x)[1]==d){ x &lt;- t(x) } for(ii in 1:d){ x[,ii] &lt;- (x[,ii]==Cbox[ii,2]) - (x[,ii]==Cbox[ii,1]) } return(x) } #&#39; sample.region &lt;- function(cc,Cbox){ limits &lt;- NULL d &lt;- length(cc) for(i in 1:d){ if(cc[i]==-1){ limits &lt;- rbind(limits, c(-Inf,Cbox[i,1])) }else if(cc[i]==0){ limits &lt;- rbind(limits, c(-Inf,Inf)) }else{ limits &lt;- rbind(limits, c(Cbox[i,2], Inf)) } } colnames(limits) &lt;- c(&quot;lower&quot;,&quot;upper&quot;) return(limits) } #&#39; samp.trunc.normal &lt;- function(yy, zz, cc.info, bounds.info, mu.mat, Sigma.ell, dimdat){ cc &lt;- abs(cc.info)==1 nc &lt;- cc==0 d &lt;- length(cc.info) lower.info &lt;- bounds.info[1:d] upper.info &lt;- bounds.info[(d+1):(2*d)] mu &lt;- mu.mat[,zz] ## If all dimensions are censored. if(all(cc)){ sig = Sigma.ell[,,zz] if(dimdat==1) sig = as.matrix(sig) yy &lt;- tmvnsim(nsamp=1,d,lower=lower.info,upper=upper.info, mean= mu, sigma = sig)$samp ## If /not/ all dimensions are censored. } else { ## Conditional mean and variance slope &lt;- Sigma.ell[cc,nc,zz] %*% solve(Sigma.ell[nc,nc,zz]) cond.sig &lt;- Sigma.ell[cc,cc,zz] - slope %*% Sigma.ell[nc,cc,zz] cond.m &lt;- mu[cc]+slope %*% (yy[nc]-mu[nc]) ## Sample from this conditional truncated normal if(dimdat==1) cond.sig = as.matrix(cond.sig) stopifnot(&quot;matrix&quot; %in% class(cond.sig)) imputed_y = tmvnsim(nsamp = 1, length(cond.m), lower=lower.info[cc], upper = upper.info[cc], mean= cond.m, sigma = cond.sig)$samp yy[cc] &lt;- imputed_y } if(!is.numeric(yy)) browser() return(yy) } #&#39; impute.censored &lt;- function(ww, yy, zz, cc.info.mat, bounds.mat, mu.mat, Sigma.ell, dimdat){ ## Setup stopifnot(&quot;array&quot; %in% class(Sigma.ell)) if(length(zz) == 0){ ret &lt;- NULL }else if (length(zz)==1){ ret &lt;- samp.trunc.normal(yy, zz, cc.info.mat, bounds.mat, mu.mat, Sigma.ell, dimdat) } else { ret &lt;- t(sapply(1:length(zz), function(ii) samp.trunc.normal(yy[ii,], zz[ii], cc.info.mat[ii,], bounds.mat[,ii], mu.mat, Sigma.ell, dimdat))) } return(ret) } #&#39; gen.syn.dta &lt;- function(T, K, p, d=3, Cbox=NULL, Pi =NULL, avg.clust.size=100){ ### by default, d = 3 nt &lt;- rpois(n=T,lambda=avg.clust.size*K) X &lt;- t(sapply(1:p, function(pp) arima.sim(list(order=c(1,0,0), ar=pp/(pp+1)/2), n=T))) Beta &lt;- array(rnorm(K*p*d), c(d,p,K)) beta0 &lt;- matrix(rnorm(K*d), nrow=d,ncol=K) if(is.null(Pi)){ Gamma0 &lt;- matrix(rnorm(K*p), nrow= p, ncol = K) Gamma0 &lt;- t(apply(Gamma0,1,function(x) x-x[K]))/10 gamma0 &lt;- (1:K)/1 Pi &lt;- t(apply(t(X) %*% Gamma0+gamma0, 1, function(x) exp(x)/sum(exp(x)))) } Sigma &lt;- rWishart(K, 1, diag(d)) Z.list &lt;- lapply(1:T, function(tt) sample(1:K, nt[[tt]], prob = Pi[tt,],replace = TRUE)) Y.list &lt;- NULL for(t in 1:T){ Z &lt;- Z.list[[t]] Y.list[[t]] &lt;- t(sapply(Z,function(z) mvrnorm(n=1, mu = beta0[,z]+Beta[,,z]%*%X[,t],Sigma = Sigma[,,z]))) } Ytrue.list &lt;- Y.list if(is.null(Cbox)==FALSE){ Y.list &lt;- lapply(Y.list, function(x) dtaMatCensor(x,Cbox)) } return(list(Y.list=Y.list, X=X, Z.list=Z.list, nt=nt, Cbox=Cbox, K=K, Ytrue.list = Ytrue.list, Pi = Pi, beta0 = beta0, Beta = Beta, Sigma = Sigma)) } #&#39; loglik_eval &lt;- function(mu.list, chol.Sig.list, W.list, X.list, Y.list, Z.list, nt.list, simple = FALSE){ ## logPiZ &lt;- mcmapply(function(xx,yy,mm){sapply(1:K, function(kk) ## mvnfast::dmvn(yy, mm[,kk], chol.Sig.list[[kk]],log=TRUE,isChol = TRUE)) }, ## xx=X.list, yy = Y.list, mm=mu.list, mc.cores = min(n.cores, T), ## SIMPLIFY = FALSE) if(simple == TRUE){ ll.vec &lt;- sapply(1:nt.list[[1]], function(id) mvnfast::dmvn(Y.list[[1]][id,], mu.list[[1]][,Z.list[[1]][id]], chol.Sig.list[[Z.list[[1]][id]]], log=TRUE, isChol = TRUE)) out &lt;- sum(ll.vec * W.list[[1]]) / nt.list[[1]] }else{ ll.sums &lt;- mcmapply(function(ww, xx,yy,mm,zz,nt){ sum(ww * sapply(1:nt,function(id) mvnfast::dmvn(yy[id,], mm[,zz[id]], chol.Sig.list[[zz[id]]], log=TRUE,isChol = TRUE)) )}, ww = W.list, xx = X.list, yy = Y.list, mm=mu.list, zz = Z.list, nt = nt.list, mc.cores = min(n.cores, T), SIMPLIFY = TRUE) out &lt;- Reduce(&quot;+&quot;,ll.sums)/sum(unlist(nt.list)) } return(out) } "],["syntheticdata.html", "4 Generating synthetic data", " 4 Generating synthetic data Here are some simple functions to generate 1d data. This code uses data from the flowmix AOAS paper. (More generally, the MCMC function takes mainly ylist, countslist, and X as data.) There are two scenarios we will test out in our paper: One-dimensional data, two clusters. Keep censor boundaries, but move the top cluster towards top censor boundary. One-dimensional data, two clusters. Keep means constant, but move the censor boundaries towards the center. (not done yet!) First load existing cytogram data and flowmix model estimates. dat_1d = readRDS(&quot;~/Downloads/paper-data/MGL1704-hourly-paper-1d-diam.RDS&quot;) res = readRDS(&quot;~/Downloads/paper-data/1d-cvres.rds&quot;) %&gt;% .$bestres ## Take two clusters&#39; model parameters (Picoeukaryotes and Prochlorococcus) orig_model = list() orig_model$alpha = res$alpha[c(3,4),,drop=FALSE] orig_model$beta = res$beta[c(3,4)] orig_model$sigma = res$sigma[c(3,4),1,1,drop=FALSE] orig_model$dimdat = res$dimdat orig_model$numclust = res$numclust orig_model$TT = res$TT ## Covariates are the same orig_model$X = res$X ## Save the &quot;original model&quot; saveRDS(orig_model, file=file.path(&quot;~/repos/flowcut/inst/output&quot;, &quot;orig_model.RDS&quot;)) Next, weâ€™ll make several versions of this model with isignal from 0 to 10; (1) isignal=0 means the means are completely overlapping. (2) isignal=10 is the highest signal size (gap between the two means). The cluster probabilities are set to be all 1/2 everywhere. This means that the true \\(\\alpha\\) coefficients are zero. #&#39; From an original set of model parameters (|true_model|), #&#39; generate synthetic 2-cluster 1-dimensional data with equal probabilities. #&#39; #&#39; @param isignal 0 to 10, which generates the means. #&#39; #&#39; @return A list with beta, mn, alpha, prob, X, sigma, TT, numclust. #&#39; @export make_model &lt;- function(orig_model, isignal){ ## Setup stopifnot(isignal %in% 0:10) new_model = orig_model new_model$numclust = 2 ## Not used now: Renormalize the probabilities if(FALSE){ link = cbind(1, orig_model$X) %*% t(orig_model$alpha) new_model$prob = exp(link) / rowSums(exp(link)) new_model$prob %&gt;% matplot(type = &#39;l&#39;, lty = 1) } ## We are actually just going to use flat probabilities, for now. alphamat = orig_model$alpha alphamat[,-1] = 0 alphamat[,1] = 1 new_model$alpha = alphamat new_model$prob = matrix(1/2, nrow = orig_model$TT, ncol = 2) ## Take the two intercepts intp_high = orig_model$beta %&gt;% .[[1]]%&gt;% .[&quot;intp&quot;,] intp_low = orig_model$beta %&gt;% .[[2]]%&gt;% .[&quot;intp&quot;,] increment = (intp_high - intp_low)/10 ## Bring the larger mean down. new_model$beta[[1]][&quot;intp&quot;,] = intp_low + increment * isignal new_model$mn = array(NA, dim = c(orig_model$TT, 1, 2)) new_model$mn[,,1] = (cbind(1,new_model$X)) %*% (new_model$beta[[1]]) new_model$mn[,,2] = (cbind(1,new_model$X)) %*% (new_model$beta[[2]]) ## Optional: plot the means if(FALSE){ new_model$mn[,1,] %&gt;% matplot(type = &#39;l&#39;, lty = 1) } return(new_model) } par(mfrow = c(3,1)) new_model = make_model(orig_model, 0) new_model$mn %&gt;% .[,1,] %&gt;% matplot(type=&#39;l&#39;, main = paste0(&quot;isignal=&quot;, 0), ylim = c(-0.5, 0.6)) new_model = make_model(orig_model, 5) new_model$mn %&gt;% .[,1,] %&gt;% matplot(type=&#39;l&#39;, main = paste0(&quot;isignal=&quot;, 5), ylim = c(-0.5, 0.6)) new_model = make_model(orig_model, 10) new_model$mn %&gt;% .[,1,] %&gt;% matplot(type=&#39;l&#39;, main = paste0(&quot;isignal=&quot;, 10), ylim = c(-0.5, 0.6)) Then, we will generate data from this model using the function gen_1d(). #&#39; Generate 1d data with 2 clusters from a list (|true_model|) #&#39; containing true model parameters. #&#39; #&#39; @param true_model List containing beta, alpha, mn, prob, numclust. #&#39; #&#39; @return Cytograms (a |ylist| object) #&#39; @export gen_1d &lt;- function(true_model, nt = 1000){ ## Setup stopifnot(true_model$numclust == 2) TT = dim(true_model$mn)[1] ## Generate cytograms ylist = list() for(tt in 1:TT){ ## Generate memberships Samples |nt| memberships out of (1:numclust) ## according to the cluster probabilities in |prob|. nt_by_clust = rmultinom(1, size = nt, true_model$prob[tt,]) ## draws = sample(1:numclust, size = nt, replace = TRUE, prob = true_model$prob[tt,]) draws = c(rep(1, nt_by_clust[1]), rep(2, nt_by_clust[2])) y_onetime = list() for(iclust in 1:true_model$numclust){ ntk = nt_by_clust[iclust] membership = rep(iclust, ntk) y_onetime[[iclust]] = cbind(MASS::mvrnorm(n = ntk, mu = true_model$mn[tt,,iclust], Sigma = true_model$sigma[iclust,,])) } y = do.call(rbind, y_onetime) ## Data ylist[[tt]] = y } return(ylist) } (TODO Weâ€™ll generate data particles with probability proportional to 1/biomass.) Testing this function out. ## Generate data set.seed(100) new_model = make_model(orig_model, 8) ylist = gen_1d(new_model, nt = 100) flowtrend::plot_1d(ylist, obj = new_model) ## Censor it ylist = lapply(ylist, function(y){ y = pmin(y, 0.5) }) flowtrend::plot_1d(ylist, obj = new_model) ## Form the censored &quot;box&quot; Cbox = rbind(c(-Inf, 0.5)) ## Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if `.name_repair` is omitted as of tibble 2.0.0. ## â„¹ Using compatibility `.name_repair`. ## â„¹ The deprecated feature was likely used in the flowtrend package. ## Please report the issue to the authors. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. (TODO: Maybe we will use fewer than 40 coefficients. Letâ€™s get the top 10 coefficients by importance, and only use them.) "],["gibbs-sampler.html", "5 Gibbs sampler 5.1 The main Gibbs sampler", " 5 Gibbs sampler 5.1 The main Gibbs sampler The main Gibbs sampler is called run.Gibbs.fast(). TODO items: We should write a function that makes a Cbox object. We should write what user.prior refers to. We should write what gg refers to, precisely. #&#39; Runs a gibbs sampler to estimate the posterior distribution of the flowcut #&#39; model. #&#39; #&#39; @param ylist data. #&#39; @param countlist weights (counts) for data in |ylist|. #&#39; @param X covariates; a (p x T) matrix (TODO: change code so that X is T x p). #&#39; @param Nmc Number of MCMC iterations #&#39; @param Nburn Number of burn-in iterations. #&#39; @param Cbox Censored box. #&#39; @param user.prior User-supplied prior. Otherwise, prior defaults to ___. #&#39; @param gg Size of Normal prior. #&#39; @param verbose Whether to be loud. #&#39; @param warm.start If supplied, restart the MCMC at these values. #&#39; @param tol NOT USED. #&#39; #&#39; #&#39; @return run.Gibbs.fast &lt;- function(ylist, countslist, X, numclust, Nmc = 3000, Nburn = 500, Cbox = NULL, user.prior = NULL, gg=1, verbose = FALSE, warm.start = NULL, tol = 1/1e8){ ## Basic setup TT &lt;- length(ylist) p &lt;- dim(X)[1] dimdat = ncol(ylist[[1]]) ntlist = sapply(ylist, nrow) NN &lt;- sum(ntlist) tt.impute &lt;- min(20,floor(Nburn/5)) ylist.raw &lt;- ylist ## store raw ylist ##### pre computed quantities X.list &lt;- as.list(as.data.frame(X)) Xp &lt;- rbind(1,X) Xp.list &lt;- as.list(as.data.frame(Xp)) W.sq.list &lt;- lapply(countslist, function(xx) sqrt(xx)) mt &lt;- lapply(countslist, sum)%&gt;%unlist() MM &lt;- sum(mt) XtXtT &lt;- lapply(X.list,function(x) x%*%t(x)) XtXtTp &lt;- lapply(Xp.list, function(x) x%*%t(x)) ggXtXtTp &lt;- lapply(Xp.list, function(x) x%*%t(x)/gg) XTX &lt;- X%*%t(X) XTXp &lt;- Xp%*%t(Xp) inv.XTX &lt;- Rfast::spdinv(XTX) inv.XTXp &lt;- Rfast::spdinv(XTXp) ## Y.grand.mean &lt;- Rfast::colmeans(do.call(rbind,ylist)) ## Build censored box if(!is.null(Cbox)){ Censor.list &lt;- mclapply(ylist, function(x) censorIndicator(x,Cbox), mc.cores = min(n.cores, TT)) censor.01.list &lt;- mclapply(Censor.list, function(x) apply(x,1, function(xx) sum(abs(xx))&gt;0), mc.cores = min(n.cores, TT)) censored.ylist &lt;- mcmapply(function(yy,c01) {yy[c01==TRUE,,drop=FALSE]}, yy = ylist, c01 = censor.01.list, mc.cores = min(n.cores, TT)) censored.C.list &lt;- mcmapply(function(c01,cc){cc[c01==TRUE,,drop=FALSE]}, c01 = censor.01.list, cc=Censor.list, mc.cores = min(n.cores, TT)) censored.countslist &lt;- mcmapply(function(c01,ww){ww[c01==TRUE]}, c01 = censor.01.list, w=countslist, mc.cores = min(n.cores, TT)) ntlist.censor &lt;- sapply(1:TT,function(tt) sum(censor.01.list[[tt]])) samp.region.list &lt;- lapply(1:TT, function(tt){ c01 &lt;- censor.01.list[[tt]] cc &lt;- Censor.list[[tt]] if(verbose){ print(paste(&quot;Time=&quot;,tt,&quot;, censored obs.= &quot;,sum(c01==TRUE), &quot;, censored ratio =&quot;, round(sum(c01==TRUE)/ntlist[tt],2), sep=&quot; &quot;)) } if(sum(c01==TRUE)&gt;1){ apply(cc[c01==TRUE,,drop=FALSE],1,function(xx) sample.region(xx,Cbox)) }else if(sum(c01==TRUE)==1){ matrix(sample.region(cc[c01==TRUE,,drop=FALSE],Cbox),ncol=1) }else{ NULL }}) } ##### prior specifications if(is.null(user.prior)){ nu0=dimdat nu1=p+1 S0=diag(dimdat) S1=diag(p+1) ## inv.Omega &lt;- solve(S1) } ##### initialize if(!is.null(warm.start)){ print(&quot;continue with a previous draw&quot;) Z.list &lt;- warm.start$Z.list ylist &lt;- warm.start$ylist ## Omega &lt;- warm.start$Omega beta.ell &lt;- warm.start$beta gamma.ell &lt;- warm.start$gamma Sig.ell &lt;- warm.start$Sigma Nburn &lt;- 0 ## no need of burn-in tt.impute &lt;- min(25,floor(Nburn/5)) }else{ Z.list &lt;- lapply(1:TT,function(tt) sample(1:numclust,ntlist[tt],replace = TRUE)) ## Omega &lt;- rinvwishart(1,nu1+p+1,S1)[,,1] beta.ell &lt;- array(rnorm(numclust*(p+1)*dimdat), c(dimdat,p+1,numclust)) gamma.ell &lt;- matrix(rnorm((p+1)*(numclust-1)),nrow=p+1,ncol=numclust-1) Sig.ell &lt;- rinvwishart(numclust,nu0+dimdat,S0)## %&gt;% as.matrix() } ## Omega.ell &lt;- rinvwishart(numclust-1,nu1+p+1,S1) ## beta.ell &lt;- array(rnorm(numclust*p*dimdat), c(dimdat,p,numclust)) ## beta0.ell &lt;- matrix(0,nrow=dimdat,ncol=numclust) SX.ell &lt;- array(0, c(p,p,numclust)) Sy.ell &lt;- matrix(0,nrow = dimdat, ncol = TT) Sxy.ell &lt;- array(0, c(p,dimdat,numclust)) ##### store ## burn.beta0 &lt;- array(0,c(dimdat,numclust,Nburn)) ## burn.beta &lt;- array(0,c(dimdat,p,numclust,Nburn)) burn.beta &lt;- array(0,c(dimdat,p+1,numclust,Nburn)) burn.Sigma &lt;- array(0,c(dimdat,dimdat,numclust,Nburn)) burn.gamma &lt;- array(0,c(p+1,numclust-1,Nburn)) ## burn.Omega &lt;- array(0,c(p+1,p+1,Nburn)) burn.avgloglik &lt;- rep(NA, Nburn) ## pos.beta0 &lt;- array(0,c(dimdat,numclust,Nmc)) ##pos.beta &lt;- array(0,c(dimdat,p,numclust,Nmc)) pos.beta &lt;- array(0,c(dimdat,p+1,numclust,Nmc)) pos.Sigma &lt;- array(0,c(dimdat,dimdat,numclust,Nmc)) pos.gamma &lt;- array(0,c(p+1,numclust-1,Nmc)) ##pos.Omega &lt;- array(0,c(p+1,p+1,Nmc)) pos.avgloglik &lt;- rep(NA, Nmc) ## if(is.null(Cbox)==FALSE){ ## pos.imputedimdat.Y &lt;- array(0,c(dimdat,sum(nt.censor),Nmc)) ## } if(verbose){ print(&quot;The Gibbs sampler starts now.&quot;) list.iter &lt;- c(1, Nburn+1, 1:floor((Nmc+ Nburn-1)/100)*100, Nmc + Nburn) ptm &lt;- NULL } ##### posterior sampling starts here for(jj in 1:(Nburn+Nmc)){ cat(&quot;MCMC iteration:&quot;, jj, fill = TRUE) if(verbose){ if(jj ==1 &amp; Nburn &gt; 0){ print(&quot;Burn-in period starts.&quot;) print(Sys.time()) } if(jj == tt.impute + 1){ ptm &lt;- proc.time() } if(jj ==Nburn+1 &amp; Nburn &gt; 0){ ## burn.in.last.draw &lt;- list(Z.list=Z.list,ylist=ylist) ## save(burn.in.last.draw, file = &quot;Burn-in-last-draw.Rdata&quot;) ## try(dev.off(),silent = TRUE) ## par(mfrow = c(dimdat,numclust)) ## par(mar = c(numclust,dimdat,numclust,dimdat)/1.5) ## try(for(dd in 1:dimdat){ ## for(kk in 1:numclust){ ## title &lt;- paste(&quot;beta0 traceplot&quot;, &quot;dim = &quot;, dd, &quot;, clust = &quot;, kk, sep = &quot; &quot;) ## plot(floor(Nburn/2):Nburn, ## burn.beta0[dd,kk,floor(Nburn/2):Nburn], ## type=&quot;l&quot;, main=title, lwd = 2) ## } ## },silent = TRUE) plot(burn.avgloglik[(tt.impute+1):Nburn], type=&quot;l&quot;,lwd=2) print(paste(&quot;Burn-in sample size: &quot;, Nburn, sep = &quot; &quot;)) print(&quot;Burn-in period ends.&quot;) print(&quot;Burn-in time cost per iteration, in seconds&quot;) burn.tc &lt;- (proc.time()-ptm)/(Nburn - tt.impute) print(round(burn.tc,2)) print(Sys.time()) print(&quot;Collecting posterior samples......&quot;) print(paste(&quot;Expected time to draw&quot;, Nmc, &quot;posterior samples: &quot;, round(burn.tc[3]*Nmc/60/60,2), &quot; hours&quot;, sep=&quot; &quot;)) } if(jj %in% list.iter &amp; jj &gt; Nburn){ progress(jj - Nburn,Nmc) } if(jj %in% list.iter &amp; jj &lt; Nburn+1){ progress(jj,Nburn) } } ################################################ ## experts&#39; estimation ### ################################################ mt.ell &lt;- mcmapply(function(ww,zz){ sapply(1:numclust, function(kk) sum(ww[zz==kk]))}, ww = countslist, zz = Z.list, SIMPLIFY = TRUE, mc.cores = min(n.cores, TT)) m.ell &lt;- Rfast::rowsums(mt.ell) ## nt.ell &lt;- do.call(cbind,mclapply(Z.list, function(zz){ ## sapply(1:numclust, function(kk) as.numeric(sum(zz == kk)))}, ## mc.cores = min(n.cores, T))) ## n.ell &lt;- Rfast::rowsums(nt.ell) for(ell in 1:numclust){ ## mm0t &lt;- do.call(rbind,mapply(function(xx,yy,zz){ ## Rfast::colsums(Rfast::eachrow(as.matrix(yy[zz==ell,]), beta.ell[,,ell] %*% xx,&quot;-&quot;))}, ## xx=X.list, yy = ylist, zz = Z.list, SIMPLIFY = FALSE)) ## mm0 &lt;- Rfast::colsums(mm0t)/n.ell[ell] ## beta0.ell[,ell] &lt;- mvrnorm(1, mm0, Sig.ell[,,ell]/n.ell[ell]) ## SX.ell &lt;- XTXp/gg + Reduce(&#39;+&#39;,Map(`*`, XtXtTp, nt.ell[ell,])) ## inv.SX.ell &lt;- Rfast::spdinv(SX.ell) ## (p+1) x (p+1) ## Sy.ell &lt;- do.call(rbind, mcmapply(function(yy,zz){ ## Rfast::colsums(as.matrix(yy[zz==ell,]))}, ## yy=ylist,zz=Z.list, SIMPLIFY = FALSE, ## mc.cores = min(n.cores, T))) SX.ell &lt;- XTXp/gg + Reduce(&#39;+&#39;,Map(`*`, XtXtTp, mt.ell[ell,])) inv.SX.ell &lt;- Rfast::spdinv(SX.ell) ## (p+1) x (p+1) ## Sy.ell &lt;- mcmapply(function(ww, yy, zz){ Sy.ell &lt;- mapply(function(ww, yy, zz){ t(as.matrix(ww[zz==ell])) %*% yy[zz==ell,,drop=FALSE]}, ww = countslist, yy = ylist, zz = Z.list, SIMPLIFY = TRUE) if(dimdat == 1) Sy.ell = rbind(Sy.ell) ## if(!is.numeric(Sy.ell[1])) browser() Sxy.ell &lt;- Xp %*% t(Sy.ell) ## (p+1) x d beta.ell[,,ell] &lt;- rmatnorm(M = t(Sxy.ell) %*% inv.SX.ell, U = Sig.ell[,,ell], V = inv.SX.ell, tol = .Machine$double.eps^0.95) sse &lt;- mcmapply(function(ww,xx,yy,zz) { wcrossprod.fast(Rfast::eachrow(as.matrix(yy[zz==ell,,drop=FALSE]), beta.ell[,,ell]%*%xx, &#39;-&#39;), ww[zz==ell], weighting = TRUE)}, xx = Xp.list, yy = ylist, zz=Z.list, ww = W.sq.list, SIMPLIFY = FALSE, mc.cores = min(n.cores, TT)) if(dimdat == 1) Sn.ell = sum(unlist(sse)) if(dimdat &gt; 1) Sn.ell &lt;- Reduce(&#39;+&#39;,sse) Sig.ell[,,ell] &lt;- rinvwishart(1,nu0+dimdat + m.ell[ell], S0 + Sn.ell)[,,1] } ################################################ ## expert assignment ### ################################################ ## mt.ell &lt;- mcmapply(function(ww,zz){ ## sapply(1:numclust, function(kk) sum(ww[zz==kk]))}, ## ww = countslist, zz = Z.list, SIMPLIFY = TRUE, ## mc.cores = min(n.cores, TT)) ## m.ell &lt;- Rfast::rowsums(mt.ell) ## XpGamma.abs &lt;- abs(t(gamma.ell) %*% Xp) ## numclust-1 x T ## mt.cumsum &lt;- Rfast::colCumSums(mt.ell) ## Mt.ell &lt;- rbind(nt,-sweep(mt.cumsum[-numclust,], 2, mt.cumsum[numclust,])) ## omega.tell &lt;- matrix(mcmapply(pgdraw, round(Mt.ell[-numclust,]), XpGamma.abs, ## mc.cores = min(n.cores, TT)), ## nrow=numclust-1, ncol = TT) ## kappa &lt;- mt.ell[-numclust,] - Mt.ell[-numclust,]/2 XpGamma.abs &lt;- abs(t(gamma.ell) %*% Xp) ## numclust-1 x TT ## nt.cumsum &lt;- Rfast::colCumSums(as.matrix(nt.ell)) ## Nt.ell &lt;- rbind(nt,-sweep(nt.cumsum[-numclust,], 2, nt.cumsum[numclust,])) ## omega.tell &lt;- matrix(mcmapply(pgdraw, Nt.ell[-numclust,], XpGamma.abs, ## mc.cores = min(n.cores, TT)), ## nrow=numclust-1, ncol = TT) ## kappa &lt;- nt.ell[-numclust,] - Nt.ell[-numclust,]/2 mt.cumsum &lt;- Rfast::colCumSums(as.matrix(mt.ell)) Mt.ell &lt;- rbind(mt,-sweep(mt.cumsum[-numclust,,drop=FALSE], 2, mt.cumsum[numclust,,drop=FALSE])) omega.tell &lt;- matrix(mcmapply(pgdraw, round(Mt.ell[-numclust,]), XpGamma.abs, mc.cores = min(n.cores, TT)), nrow=numclust-1, ncol = TT) kappa &lt;- mt.ell[-numclust,,drop=FALSE] - Mt.ell[-numclust,,drop=FALSE]/2 ## inv.Omega &lt;- Rfast::spdinv(Omega) for(ell in 1:(numclust-1)){ V.omell &lt;- Rfast::spdinv(Reduce(&#39;+&#39;, Map(&#39;*&#39;,XtXtTp, omega.tell[ell,]))) ##+diag(p+1)/TT ) Mod2 m.omell &lt;- V.omell%*% Reduce(&#39;+&#39;, Map(&#39;*&#39;,Xp.list,kappa[ell,])) gamma.ell[,ell] &lt;- Rfast::rmvnorm(1,m.omell, V.omell) } XpGamma &lt;- t(gamma.ell) %*% Xp ## K-1 x TT pi.sb &lt;- 1/(1+exp(-XpGamma)) pi.mn &lt;- apply(pi.sb,2,SB2MN) logpi.list &lt;- mclapply(1:TT,function(t) log(pi.mn[,t]), mc.cores = min(n.cores,TT)) chol.Sig.ell &lt;- apply(Sig.ell,3, chol) if(dimdat == 1) chol.Sig.ell = rbind(chol.Sig.ell) chol.Sig.list &lt;- lapply(1:numclust,function(kk) matrix(chol.Sig.ell[,kk],nrow = dimdat)) mu.list &lt;- lapply(1:TT, function(tt){ one_mu = sapply(1:numclust, function(kk){ beta.ell[,,kk,drop=FALSE] %*% Xp[,tt,drop=FALSE] }) if(dimdat==1) one_mu = rbind(one_mu) return(one_mu) }) # beta0.ell[,kk] + beta.ell[,,kk] %*% X[,tt])) logPiZ &lt;- mcmapply(function(ww, xx, yy, mm, pp){ sapply(1:numclust, function(kk) mvnfast::dmvn(yy, mm[,kk], chol.Sig.list[[kk]], log=TRUE, isChol = TRUE) + pp[kk])}, ## mod here ww = countslist, xx =X.list, yy = ylist, mm = mu.list, pp=logpi.list, mc.cores = min(n.cores, TT), SIMPLIFY = FALSE) Z.list &lt;- mclapply(logPiZ, function(pp) apply(pp,1, function(lpi) sample(1:numclust,1,prob=softmax(lpi))), mc.cores = min(n.cores, TT)) ## mt.ell &lt;- mcmapply(function(ww,zz){ ## sapply(1:numclust, function(kk) sum(ww[zz==kk]))}, ## ww = countslist, zz = Z.list, SIMPLIFY = TRUE, ## mc.cores = min(n.cores, TT)) ## m.ell &lt;- Rfast::rowsums(mt.ell) ## print(sort(round(n.ell/NN,3))) ## print(min(n.ell)) ################################################ ## censored data imputation ################################################ if((jj&gt; tt.impute | !is.null(warm.start)) &amp; !is.null(Cbox)){ ## if(is.null(Cbox)==FALSE){ censored.Z.list &lt;- mcmapply(function(c01,zz){zz[c01==TRUE]}, c01 = censor.01.list, zz=Z.list, mc.cores = min(n.cores, TT)) ## imputed.ylist &lt;- mclapply(1:TT, function(tt) { imputed.ylist &lt;- lapply(1:TT, function(tt){ yy = impute.censored(ww = censored.countslist[[tt]], yy = censored.ylist[[tt]], zz = censored.Z.list[[tt]], cc.info.mat = censored.C.list[[tt]], bounds.mat = samp.region.list[[tt]], mu.mat = mu.list[[tt]], Sigma.ell = Sig.ell, dimdat = dimdat) }) ## mc.cores = min(n.cores, TT), mc.preschedule = FALSE) for(tt in 1:TT){ ylist[[tt]][censor.01.list[[tt]]==TRUE,] &lt;- imputed.ylist[[tt]] } } loglik &lt;- loglik_eval(mu.list, chol.Sig.list, countslist, X.list, ylist, Z.list, as.list(ntlist), simple = TRUE) ## print(sort(round(n.ell/NN,3))) ## print(sort(round(m.ell/MM,3))) if(jj %% 10 == 0) print(paste(&quot;avg loglikelihood: &quot;, round(loglik,2), sep=&quot; &quot;)) ################################################ ## collecting posterior samples ################################################ if(jj &gt;Nburn){ ### pos.beta0[,,jj-Nburn] &lt;- beta0.ell pos.beta[,,,jj-Nburn] &lt;- beta.ell pos.Sigma[,,,jj-Nburn] &lt;- Sig.ell pos.gamma[,,jj-Nburn] &lt;- gamma.ell ## pos.Omega[,,,jj-Nburn] &lt;- Omega.ell ## pos.Omega[,,jj-Nburn] &lt;- Omega pos.avgloglik[jj-Nburn] &lt;- loglik ## if(is.null(Cbox)==FALSE){ ## pos.imputed.Y[,,jj-Nburn] &lt;- matrix(unlist(imputed.ylist),nrow = d) ## } } else{ ### burn.beta0[,,jj] &lt;- beta0.ell burn.beta[,,,jj] &lt;- beta.ell burn.Sigma[,,,jj] &lt;- Sig.ell burn.gamma[,,jj] &lt;- gamma.ell ## burn.Omega[,,,jj] &lt;- Omega.ell ## burn.Omega[,,jj] &lt;- Omega burn.avgloglik[jj] &lt;- loglik } } if(verbose ){ print(&quot;All work is done.&quot;) print(paste(&quot;Stored MCMC sample size: &quot;, Nmc, sep = &quot; &quot;)) print(Sys.time()) print(&quot;total time cost, in min&quot;) print(round((proc.time()-ptm)/60,1)) print(&quot;total time cost, in hours&quot;) print(round((proc.time()-ptm)/60/60,2)) print(&quot;time cost per iteration, in seconds&quot;) print((proc.time()-ptm)/(Nburn+Nmc - tt.impute)) } if(is.null(Cbox)){ ret &lt;- list( ## burn.beta0=burn.beta0, burn.beta=burn.beta,burn.Sigma=burn.Sigma, burn.gamma=burn.gamma, ## burn.Omega=burn.Omega, ## pos.beta0=pos.beta0, pos.beta=pos.beta,pos.Sigma=pos.Sigma, pos.gamma=pos.gamma, ## pos.Omega=pos.Omega, burn.avgloglik=burn.avgloglik, pos.avgloglik=pos.avgloglik) }else{ ret &lt;- list( ## burn.beta0 = burn.beta0, burn.beta = burn.beta, burn.Sigma = burn.Sigma, burn.gamma = burn.gamma, ## burn.Omega = burn.Omega, ## pos.beta0 = pos.beta0, pos.beta = pos.beta, pos.Sigma = pos.Sigma, pos.gamma = pos.gamma, ## pos.Omega = pos.Omega, pos.imputed.Y = do.call(rbind,imputed.ylist), burn.avgloglik = burn.avgloglik, pos.avgloglik = pos.avgloglik, raw.ylist = ylist.raw, last.ylist = ylist, last.Z.list = Z.list, last.gamma = gamma.ell, ## last.Omega = Omega, last.beta = beta.ell, last.Sigma = Sig.ell ) } return(ret) } ## benchmark(&quot;ss&quot;={sapply(1:TT, function(t) sapply(1:(numclust-1), function(kk) ## pgdraw(Nt.ell[kk,t],abs(XpGamma[kk,t]))))}, ## &quot;mcmapp&quot;={matrix(mcmapply(pgdraw, Nt.ell[-numclust,], abs(XpGamma), ## mc.cores = min(n.cores, TT)), ## nrow=numclust-1, ncol = TT)}, ## &quot;mapp&quot;={matrix(mapply(pgdraw, Nt.ell[-numclust,], abs(XpGamma)), ## nrow=numclust-1, ncol = TT)}, ## replications = 10, ## columns = c(&quot;test&quot;, &quot;replications&quot;, &quot;elapsed&quot;, ## &quot;relative&quot;, &quot;user.self&quot;, &quot;sys.self&quot;)) "],["simulations.html", "6 Simulations", " 6 Simulations Refer back to the data generation in @ref{syntheticdata}. We will be top-censoring the data at 0.5. Before censoring, this is what the data looks like. ## Load the &quot;original&quot; model orig_model = readRDS(file=file.path(&quot;~/repos/flowcut/inst/output&quot;, &quot;orig_model.RDS&quot;)) ## Generate data set.seed(100) isignal = 8 new_model = make_model(orig_model, isignal) ylist = gen_1d(new_model, nt = 100) flowtrend::plot_1d(ylist, obj = new_model) After censoring, this is it. ## Censor it ylist = lapply(ylist, function(y){ y = pmin(y, 0.5) }) flowtrend::plot_1d(ylist, obj = new_model) We need to specify a few things (1) like the censoring limits Cbox and (2) countslist before running the MCMC. ## Form the censoring &quot;box&quot; Cbox = rbind(c(-Inf, 0.5)) ## Counts are all equal for now countslist = lapply(ylist, function(y){ rep(1, nrow(y)) }) ## Save the metadata datobj = list(ylist=ylist, countslist=countslist, Cbox=Cbox, X=orig_model$X) saveRDS(datobj, file.path(&quot;~/repos/flowcut/inst/output&quot;, paste0(&quot;isignal-&quot;, isignal, &quot;-datobj.RDS&quot;))) We also need some prior elicitation to prevent the cluster means from changing too much across time. (code copy-pasted as-is for now, not meant to be run) ############################## ###### prior elicitation ############################## d &lt;- 3 p &lt;- 39 X &lt;- t(readRDS(&quot;pre-censor-datobj.RDS&quot;)$X) nu0=d nu1=p+1 S0=diag(d) S1=diag(p+1) inv.XTX &lt;- solve(tcrossprod(X)) dim(inv.XTX) ## Sig.ell &lt;- rinvwishart(1,nu0+d,S0)[,,1] ## gg &lt;- 1 ## beta.ell &lt;- rmatnorm(M = matrix(0,d,p), ## U = Sig.ell, ## V = inv.XTX*gg, ## tol = .Machine$double.eps^0.5) ## mean.vec &lt;- apply(beta.ell%*% X,1,mean) ## l2.norm &lt;- mean(apply(beta.ell%*% X,2,function(xx) ## crossprod(xx-mean.vec))) ## hist(apply(beta.ell%*% X,2,function(xx) ## crossprod(xx-mean.vec)),breaks = &quot;FD&quot;) ball.deviance &lt;- function(gg,rr,X, Nmc=5000, nu0=d, nu1=p+1, S0=diag(d), S1=diag(p+1), simple= TRUE){ inv.XTX &lt;- solve(tcrossprod(X)) ms.deviance &lt;- rep(NA,Nmc) Sig.ell &lt;- rinvwishart(Nmc,nu0+d,S0) beta.ell &lt;- apply(Sig.ell,3,function(xx) as.matrix(rmatnorm(M = matrix(0,d,p), U = xx, V = inv.XTX*gg, tol = .Machine$double.eps^0.5)), simplify = FALSE) xb &lt;- lapply(beta.ell, function(bb) bb%*% X) mean.vec &lt;- lapply(xb, function(bb) apply(bb,1,mean)) ms.deviance &lt;- mapply(function(xx,mm){ mean(apply(xx,2,function(cols) crossprod(cols-mm))) }, xx=xb,mm=mean.vec) prob &lt;- mean(ms.deviance &gt; rr^2) if(simple){ return(list(gg=gg,rr=rr,prob=prob)) }else{ return(list(gg = gg, rr = rr, prob=prob, msd = ms.deviance)) } } gglist &lt;- as.list(1:100/100) plist &lt;- mclapply(gglist,function(gg) ball.deviance(gg,0.5,X,Nmc=1e4)$prob, mc.cores = min(n.cores, length(gglist))) plot(gglist,plist,type = &quot;l&quot;) abline(h=0.05,lwd=2,col = &quot;red&quot;) abline(h=0.01,lwd=2,col = &quot;red&quot;) lines(gglist,lowess(plist~gglist,f=0.3)$y,lwd=2,col=&quot;blue&quot;) hist(ball.deviance(0.01,0.5,X)$msd, breaks = &quot;FD&quot;) hist(ball.deviance(0.1,0.5,X)$msd, breaks = &quot;FD&quot;) hist(ball.deviance(0.2,0.5,X)$msd, breaks = &quot;FD&quot;) hist(ball.deviance(0.5,0.5,X)$msd, breaks = &quot;FD&quot;) hist(ball.deviance(1,0.5,X)$msd, breaks = &quot;FD&quot;) hist(ball.deviance(2,0.5,X)$msd, breaks = &quot;FD&quot;) Next, we run the MCMC. ## Run the MCMC Nmc &lt;- 1e3 * 5 Nburn &lt;- 500 Gibbs.res &lt;- run.Gibbs.fast(ylist = datobj$ylist, countslist = datobj$countslist, numclust = 2, Nmc = Nmc, Nburn = Nburn, gg = 0.1, X = t(datobj$X), Cbox = datobj$Cbox, verbose = TRUE) ## Save the results saveRDS(Gibbs.res, file.path(&quot;~/repos/flowcut/inst/output&quot;, paste0(&quot;isignal-&quot;, isignal, &quot;-gibbs.RDS&quot;))) "],["real-data-example.html", "7 Real data example", " 7 Real data example We run the Gibbs sampler on real data. Weâ€™ll load the data, process it, then feed it into the MCMC. TODO: bundle the Cbox into a make_Cbox() function. Why are we doing more.censor() manually? Simplify/streamline this. ## Load the code for running MCMC ## codedir = &quot;~/Dropbox/Apps/Overleaf/censor-flowmix/BMEcensor/code/&quot; codedir = &quot;~/Dropbox/Apps/Overleaf/censor-flowmix/BMEcensor/code/&quot; source(file.path(codedir, &#39;BME-functions.r&#39;)) ## Load dataset datadir = &quot;~/Dropbox/research-new/censored-flowmix/code/data&quot; dta &lt;- readRDS(file.path(datadir, &quot;pre-censor-datobj.RDS&quot;)) ## Assign data to objects ylist &lt;- dta$ylist TT &lt;- length(ylist) d &lt;- 3 countslist = dta$countslist ## Define censor limits bounds.lower &lt;- rowMins(matrix(unlist( lapply(dta$ylist, function(xx) colMins(xx,value = TRUE))), nrow = d), value = TRUE) bounds.upper &lt;- rowMaxs(matrix(unlist( lapply(dta$ylist, function(xx) colMaxs(xx,value = TRUE))), nrow = d), value = TRUE) ## Censor the first dimension a bit more Cbox &lt;- cbind(signif(log(bounds.lower),5), log(bounds.upper)) more.censor &lt;- function(ymat,bd){ cbind(sapply(ymat[,1], function(xx) ifelse(xx&lt;bd, bd, xx)), ymat[,c(2,3)]) } ylist &lt;- mclapply(dta$ylist, function(yy){ more.censor(log(yy),Cbox[1,1]), }, mc.cores = min(n.cores, TT)) ## Checking that censoring is done properly assertthat::assert_that(all(rowMins(matrix(unlist( lapply(ylist, function(xx) colMins(xx,value = TRUE))), nrow = d), value = TRUE) == Cbox[,1])) assertthat::assert_that(all(rowMaxs(matrix(unlist( lapply(ylist, function(xx) colMaxs(xx,value = TRUE))), nrow = d), value = TRUE) == Cbox[,2])) ## Clean data datobj &lt;- list(ylist = ylist, countslist = dta$countslist, X = dta$X, numclust = 10, Cbox=Cbox) ## Run the MCMC Nmc &lt;- 1e3*5 Nburn &lt;- 500 K &lt;- 10 Gibbs.res0 &lt;- run.Gibbs.fast(ylist = datobj$ylist, countslist = datobj$countslist, X = datobj$X, numclust = datobj$numclust, gg = 0.1, Nmc = Nmc, Nburn = Nburn, Cbox = datobj$Cbox, verbose = TRUE, warm.start = NULL) "],["documenting-the-package-and-building.html", "8 Documenting the package and building", " 8 Documenting the package and building We finish by running commands that will document, build, and install the package. It may also be a good idea to check the package from within this file. litr::document() # &lt;-- use instead of devtools::document() ## â„¹ Updating flowcut documentation ## â„¹ Loading flowcut ## Warning: [run.Gibbs.fast.R:19] @return requires a value ## Writing &#39;NAMESPACE&#39; ## Writing &#39;flowcut-package.Rd&#39; ## Writing &#39;gen_1d.Rd&#39; ## Writing &#39;make_model.Rd&#39; ## Writing &#39;run.Gibbs.fast.Rd&#39; "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
